{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is PyTorch?\n",
    "\n",
    "Itâ€™s a Python based scientific computing package targeted at two sets of audiences:\n",
    "\n",
    "-  Tensorial library that uses the power of GPUs\n",
    "-  A deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "## Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # <Ctrl> / <Shift> + <Return>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'sq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msq\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'sq'"
     ]
    }
   ],
   "source": [
    "torch.sq  # <Tab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about all `*Tensor`s?\n",
    "# Press <esc> to get out of help\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Module()  # <Shift>+<Tab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate your functions / classes!\n",
    "torch.nn.Module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Module??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping to Bash: magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 904\r\n",
      "drwxrwxr-x  8 robesafe robesafe   4096 abr 20 02:41 .\r\n",
      "drwxrwxr-x  3 robesafe robesafe   4096 abr 19 02:07 ..\r\n",
      "-rw-rw-r--  1 robesafe robesafe  33656 abr 19 03:29 00-logic_neuron_programming.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  19570 abr 20 02:41 01-tensor_tutorial.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   6735 abr 19 02:08 02-space_stretching.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   6828 abr 19 02:08 03-autograd_tutorial.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   7425 abr 19 02:08 04-spiral_classification.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   9547 abr 19 02:08 05-regression.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  13912 abr 19 02:08 06-convnet.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   8778 abr 19 02:08 07-listening_to_kernels.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  23604 abr 19 02:08 08-seq_classification.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   7442 abr 19 02:08 09-echo_data.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   7473 abr 19 02:08 10-autoencoder.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  10352 abr 19 02:08 11-VAE.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  19816 abr 19 02:08 12-regularization.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe   4479 abr 19 02:08 13-bayesian_nn.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  13117 abr 19 02:08 14-truck_backer-upper.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe  25973 abr 19 02:08 15-transformer.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe 617576 abr 19 02:08 16-gated_GCN.ipynb\r\n",
      "-rw-rw-r--  1 robesafe robesafe     16 abr 19 02:08 apt.txt\r\n",
      "drwxrwxr-x 21 robesafe robesafe   4096 abr 19 02:08 docs\r\n",
      "-rw-rw-r--  1 robesafe robesafe    257 abr 19 02:08 environment.yml\r\n",
      "drwxrwxr-x  3 robesafe robesafe   4096 abr 19 02:08 extra\r\n",
      "drwxrwxr-x  8 robesafe robesafe   4096 abr 19 03:34 .git\r\n",
      "-rw-rw-r--  1 robesafe robesafe    252 abr 19 02:08 .gitignore\r\n",
      "-rw-rw-r--  1 robesafe robesafe     94 abr 19 02:08 .gitmodules\r\n",
      "drwxrwxr-x  2 robesafe robesafe   4096 abr 19 03:41 .ipynb_checkpoints\r\n",
      "-rw-rw-r--  1 robesafe robesafe    281 abr 19 02:08 LICENSE.md\r\n",
      "-rw-rw-r--  1 robesafe robesafe   3857 abr 19 02:08 README.md\r\n",
      "drwxrwxr-x  2 robesafe robesafe   4096 abr 19 02:08 res\r\n",
      "drwxrwxr-x  2 robesafe robesafe   4096 abr 19 02:08 slides\r\n"
     ]
    }
   ],
   "source": [
    "# List all the files in the current directory\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679 00-logic_neuron_programming.ipynb\n",
      "955 01-tensor_tutorial.ipynb\n",
      "273 02-space_stretching.ipynb\n",
      "331 03-autograd_tutorial.ipynb\n",
      "294 04-spiral_classification.ipynb\n",
      "362 05-regression.ipynb\n",
      "458 06-convnet.ipynb\n",
      "337 07-listening_to_kernels.ipynb\n",
      "659 08-seq_classification.ipynb\n",
      "257 09-echo_data.ipynb\n",
      "264 10-autoencoder.ipynb\n",
      "353 11-VAE.ipynb\n",
      "648 12-regularization.ipynb\n",
      "195 13-bayesian_nn.ipynb\n",
      "422 14-truck_backer-upper.ipynb\n",
      "771 15-transformer.ipynb\n",
      "1083 16-gated_GCN.ipynb\n",
      "1 apt.txt\n",
      "20 environment.yml\n",
      "4 LICENSE.md\n",
      "71 README.md\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# List all the files but with cleaner outputs for readability\n",
    "for f in $(ls *.*); do\n",
    "    echo $(wc -l $f)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting some general help\n",
    "%magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['## Python native data types\\n',\n",
       "   '\\n',\n",
       "   'Python has many native datatypes. Here are the important ones:\\n',\n",
       "   '\\n',\n",
       "   ' - **Booleans** are either `True` or `False`.\\n',\n",
       "   ' - **Numbers** can be integers (1 and 2), floats (1.1 and 1.2), fractions (1/2 and 2/3), or even complex numbers.\\n',\n",
       "   ' - **Strings** are sequences of Unicode characters, e.g. an html document.\\n',\n",
       "   ' - **Lists** are ordered sequences of values.\\n',\n",
       "   ' - **Tuples** are ordered, immutable sequences of values.\\n',\n",
       "   ' - **Sets** are unordered bags of values.\\n',\n",
       "   ' - **Dictionaries** are unordered bags of key-value pairs.\\n',\n",
       "   ' \\n',\n",
       "   'See [here](http://www.diveintopython3.net/native-datatypes.html) for a complete overview.\\n',\n",
       "   '\\n',\n",
       "   '### More resources\\n',\n",
       "   '\\n',\n",
       "   ' 1. Brief Python introduction [here](https://learnxinyminutes.com/docs/python3/).\\n',\n",
       "   ' 2. Full Python tutorial [here](https://docs.python.org/3/tutorial/).\\n',\n",
       "   ' 3. A Whirlwind Tour of Python [here](https://github.com/jakevdp/WhirlwindTourOfPython).\\n',\n",
       "   ' 4. Python Data Science Handbook [here](https://github.com/jakevdp/PythonDataScienceHandbook).']},)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Python native data types\\n\",\n",
    "    \"\\n\",\n",
    "    \"Python has many native datatypes. Here are the important ones:\\n\",\n",
    "    \"\\n\",\n",
    "    \" - **Booleans** are either `True` or `False`.\\n\",\n",
    "    \" - **Numbers** can be integers (1 and 2), floats (1.1 and 1.2), fractions (1/2 and 2/3), or even complex numbers.\\n\",\n",
    "    \" - **Strings** are sequences of Unicode characters, e.g. an html document.\\n\",\n",
    "    \" - **Lists** are ordered sequences of values.\\n\",\n",
    "    \" - **Tuples** are ordered, immutable sequences of values.\\n\",\n",
    "    \" - **Sets** are unordered bags of values.\\n\",\n",
    "    \" - **Dictionaries** are unordered bags of key-value pairs.\\n\",\n",
    "    \" \\n\",\n",
    "    \"See [here](http://www.diveintopython3.net/native-datatypes.html) for a complete overview.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### More resources\\n\",\n",
    "    \"\\n\",\n",
    "    \" 1. Brief Python introduction [here](https://learnxinyminutes.com/docs/python3/).\\n\",\n",
    "    \" 2. Full Python tutorial [here](https://docs.python.org/3/tutorial/).\\n\",\n",
    "    \" 3. A Whirlwind Tour of Python [here](https://github.com/jakevdp/WhirlwindTourOfPython).\\n\",\n",
    "    \" 4. Python Data Science Handbook [here](https://github.com/jakevdp/PythonDataScienceHandbook).\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a tensor of size 2x3x4\n",
    "t = torch.Tensor(2, 3, 4)\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of the tensor\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t size: 2 Ã— 3 Ã— 4\n"
     ]
    }
   ],
   "source": [
    "# t.size() is a classic tuple =>\n",
    "print('t size:', ' \\u00D7 '.join(map(str, t.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point in a 24 dimensional space\n",
      "organised in 3 sub-dimensions\n"
     ]
    }
   ],
   "source": [
    "# prints dimensional space and sub-dimensions\n",
    "print(f'point in a {t.numel()} dimensional space')\n",
    "print(f'organised in {t.dim()} sub-dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7., 5., 6., 8.],\n",
       "         [9., 0., 6., 0.],\n",
       "         [2., 8., 1., 3.]],\n",
       "\n",
       "        [[1., 4., 4., 6.],\n",
       "         [3., 2., 8., 7.],\n",
       "         [6., 2., 6., 3.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mind the underscore!\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
    "t.random_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7., 5., 6., 8.],\n",
       "         [9., 0., 6., 0.],\n",
       "         [2., 8., 1., 3.]],\n",
       "\n",
       "        [[1., 4., 4., 6.],\n",
       "         [3., 2., 8., 7.],\n",
       "         [6., 2., 6., 3.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 5., 6., 8., 9., 0., 6., 0.],\n",
       "        [2., 8., 1., 3., 1., 4., 4., 6.],\n",
       "        [3., 2., 8., 7., 6., 2., 6., 3.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This resizes the tensor permanently \n",
    "r = torch.Tensor(t) # create a tensor using the content of t\n",
    "r.resize_(3, 8)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
    "r.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This *is* important, sigh...\n",
    "s = r.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place fill of 1's\n",
    "s.fill_(1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we cloned r, even though we did an in-place operation, this doesn't affect r\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors (1D Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a 1D tensor of integers 1 to 4\n",
    "v = torch.Tensor([1, 2, 3, 4])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim: 1, size: 4\n"
     ]
    }
   ],
   "source": [
    "# Print number of dimensions (1D) and size of tensor\n",
    "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 2., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.Tensor([1, 0, 2, 0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 6., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "v * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
    "v @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 8., 2., 8., 4.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place replacement of random number from 0 to 10\n",
    "x = torch.Tensor(5).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: 4.0, last: 4.0\n"
     ]
    }
   ],
   "source": [
    "print(f'first: {x[0]}, last: {x[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8., 2.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sub-Tensor [from:to)\n",
    "x[1:2 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with integers ranging from 1 to 5, excluding 5\n",
    "v = torch.arange(1, 4 + 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4,  9, 16]) tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Square all elements in the tensor\n",
    "print(v.pow(2), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices (2D Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x4 tensor\n",
    "m = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -- 4 -- torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the total number of elements, hence num-el (number of elements)\n",
    "m.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing row 0, column 2 (0-indexed)\n",
    "m[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing row 0, column 2 (0-indexed)\n",
    "m[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing column 1, all rows (returns size 2)\n",
    "m[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing column 1, all rows (returns size 2x1)\n",
    "m[:, [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexes row 0, all columns (returns 1x4)\n",
    "m[[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5., 3., 7.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexes row 0, all columns (returns size 4)\n",
    "m[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor of numbers from 1 to 5 (excluding 5)\n",
    "v = torch.arange(1., 4 + 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49., 47.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar product\n",
    "m @ v # (2 x 4) x (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(m.shape)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
    "m[0, :] @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated by \n",
    "m[[1], :] @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6218, 5.5756, 3.4386, 7.8593],\n",
       "        [4.0520, 2.8316, 1.0444, 9.4674]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a random tensor of size 2x4 to m\n",
    "m + torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6890, 4.9424, 2.1668, 6.9557],\n",
       "        [3.5896, 1.4085, 0.0914, 8.0594]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract a random tensor of size 2x4 to m\n",
    "m - torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7813, 2.7248, 2.3900, 0.3062],\n",
       "        [3.6950, 0.0443, 0.5355, 4.9571]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply a random tensor of size 2x4 to m # Element-wise!!!!\n",
    "m * torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0764,  6.0024, 14.9412, 12.4905],\n",
       "        [ 6.6561,  3.9324,  4.5552, 11.8328]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide m by a random tensor of size 2x4 # Element-wise!!!!\n",
    "m / torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [5., 2.],\n",
       "        [3., 1.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
    "m.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [5., 2.],\n",
       "        [3., 1.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as\n",
    "m.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from 3 to 8, with each having a space of 1\n",
    "torch.arange(3., 8 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7000,  2.7000, -0.3000])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from 5.7 to -2.1 with each having a space of -3\n",
    "torch.arange(5.7, -2.1, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,\n",
       "         5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,\n",
       "         7.7368, 8.0000]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a 1D tensor of steps equally spaced points between start=3, end=8 and steps=20\n",
    "torch.linspace(3, 8, 20).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with 0's\n",
    "torch.zeros(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with 1's\n",
    "torch.ones(3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with the diagonal filled with 1\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default plots\n",
    "from res.plot_lib import set_default\n",
    "from matplotlib import pyplot as plt\n",
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Numpy bridge!\n",
    "plt.hist(torch.randn(1000).numpy(), 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.randn(10**6).numpy(), 100);  # how much does this chart weight?\n",
    "# use rasterized=True for SVG/EPS/PDF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.rand(10**6).numpy(), 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get what kind of tensor types\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is basically a 64 bit float tensor\n",
    "m_double = m.double()\n",
    "m_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 3, 7],\n",
       "        [4, 2, 1, 9]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates a tensor of type int8\n",
    "m_byte = m.byte()\n",
    "m_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 5., 3., 7.],\n",
       "       [4., 2., 1., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts tensor to numpy array\n",
    "m_np = m.numpy()\n",
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  5.,  3.,  7.],\n",
       "       [ 4.,  2.,  1.,  9.]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place fill of column 0 and row 0 with value -1\n",
    "m_np[0, 0] = -1\n",
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of integers ranging from 0 to 4\n",
    "import numpy as np\n",
    "n_np = np.arange(5)\n",
    "n = torch.from_numpy(n_np)\n",
    "print(n_np, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140716032247504 tensor([  0, 128, 256, 384, 512])\n",
      "140716027941776 [  0 128 256 384 512]\n"
     ]
    }
   ],
   "source": [
    "# In-place multiplication of all elements by 2 for tensor n\n",
    "# Because n is essentiall n_np, not a clone, this affects n_np\n",
    "n.mul_(2)\n",
    "n_np\n",
    "print(id(n),n)\n",
    "print(id(n_np), n_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) tensor([[5., 6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Creates two tensor of size 1x4\n",
    "a = torch.Tensor([[1, 2, 3, 4]])\n",
    "b = torch.Tensor([[5, 6, 7, 8]])\n",
    "print(a.size(), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate on axis 0, so you get 2x4\n",
    "torch.cat((a, b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate on axis 1, so you get 1x8\n",
    "torch.cat((a, b), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much more\n",
    "\n",
    "There's definitely much more, but this was the basics about `Tensor`s fun.\n",
    "\n",
    "*Torch* full API should be read at least once.\n",
    "Hence, go [here](https://pytorch.org/docs/stable/index.html).\n",
    "You'll find 100+ `Tensor` operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
